from sentence_transformers import SentenceTransformer
from pyvi.ViTokenizer import tokenize
from chromadb import PersistentClient
import json
from tqdm import tqdm

# ====== CONFIG ======
MODEL_NAME = "AITeamVN/Vietnamese_Embedding"
INPUT_FILE = "../data/chunks_1k.jsonl"          
CHROMA_PATH = "../chroma_db"                    
COLLECTION_NAME = "vbpl"
BATCH_SIZE = 5000

# ====== LOAD MODEL ======
print(f"üì¶ ƒêang load model: {MODEL_NAME}")
model = SentenceTransformer(MODEL_NAME, device="cuda")

# ====== LOAD D·ªÆ LI·ªÜU ======
print(f"üìñ ƒê·ªçc d·ªØ li·ªáu t·ª´ {INPUT_FILE} ...")
with open(INPUT_FILE, "r", encoding="utf-8") as f:
    data = [json.loads(line) for line in f]

texts = [d["text"] for d in data]
print(f"üîπ T·ªïng s·ªë chunks: {len(texts):,}")

# ====== TOKENIZE ======
print("üî§ Tokenizing ti·∫øng Vi·ªát ...")
tokenized = [tokenize(t) for t in tqdm(texts, desc="Tokenizing")]

# ====== EMBED ======
print("‚öôÔ∏è ƒêang t·∫°o embeddings b·∫±ng GPU ...")
embeddings = model.encode(
    tokenized,
    batch_size=32,
    show_progress_bar=True,
    convert_to_numpy=True
)

# ====== L∆ØU THEO BATCH V√ÄO CHROMA ======
print(f"üíæ L∆∞u v√†o ChromaDB: {CHROMA_PATH}")
client = PersistentClient(path=CHROMA_PATH)

# N·∫øu collection ƒë√£ t·ªìn t·∫°i ‚Üí l·∫•y l·∫°i thay v√¨ t·∫°o m·ªõi
try:
    collection = client.get_collection(COLLECTION_NAME)
    print(f"‚ö†Ô∏è Collection '{COLLECTION_NAME}' ƒë√£ t·ªìn t·∫°i, ghi th√™m d·ªØ li·ªáu.")
except:
    collection = client.create_collection(COLLECTION_NAME)
    print(f"üÜï T·∫°o collection m·ªõi: {COLLECTION_NAME}")

# Ghi theo batch an to√†n
for i in range(0, len(data), BATCH_SIZE):
    batch_data = data[i:i+BATCH_SIZE]
    batch_emb = embeddings[i:i+BATCH_SIZE].tolist()

    collection.add(
        ids=[d["item_id"] for d in batch_data],
        embeddings=batch_emb,
        metadatas=[{
            "title": d["title"],
            "section_path": d.get("section_path", "")
        } for d in batch_data],
        documents=[d["text"] for d in batch_data]
    )

    print(f"‚úÖ Batch {i//BATCH_SIZE + 1}: ƒë√£ th√™m {len(batch_data)} chunks")

print(f"\nüéâ Ho√†n t·∫•t! T·ªïng c·ªông {len(data):,} chunks ƒë√£ l∆∞u v√†o '{COLLECTION_NAME}' trong '{CHROMA_PATH}'")

# ====== KI·ªÇM TRA L·∫†I S·ªê L∆Ø·ª¢NG ======
print(f"üìä T·ªïng vectors hi·ªán c√≥ trong collection: {collection.count()}")
