import json, re, unicodedata
from urllib.parse import urlparse, parse_qs
from tqdm import tqdm
from collections import defaultdict

# =========================
# üìÅ ƒê∆Ø·ªúNG D·∫™N FILE
# =========================
INPUT_FILE  = "../data/vbpl_data_hoan_chinh.jsonl"
OUTPUT_FILE = "../data/vbpl_data_clean.jsonl"
LOG_FILE    = "../data/clean_log.txt"

# =========================
# üî§ H√ÄM CHU·∫®N H√ìA CHU·ªñI
# =========================
def normalize_unicode(s: str) -> str:
    if not isinstance(s, str): return ""
    s = unicodedata.normalize("NFC", s)
    return (s.replace("\u00A0", " ")
              .replace("\u200B", "")
              .replace("\ufeff", "")
              .replace("\r", " "))

def clean_space(s: str) -> str:
    if not isinstance(s, str): return ""
    s = re.sub(r'\s+', ' ', s)
    return s.strip()

# =========================
# üß© H√ÄM L·∫§Y ID ·ªîN ƒê·ªäNH
# =========================
def get_unique_id(item):
    """T·∫°o ID duy nh·∫•t d·ª±a tr√™n ItemID trong URL ho·∫∑c fallback theo hash."""
    url = item.get("url_goc", "")
    title = item.get("tieu_de", "")
    attrs = item.get("thuoc_tinh", {}) or {}

    try:
        qs = parse_qs(urlparse(url).query)
        item_id = qs.get("ItemID", [None])[0]
        if item_id:
            return f"vbpl_{item_id}"
    except Exception:
        pass

    sig = f"{title}_{attrs.get('S·ªë k√Ω hi·ªáu','')}_{attrs.get('Ng√†y ban h√†nh','')}"
    return f"auto_{abs(hash(sig))}"

# =========================
# üßπ H√ÄM L√ÄM S·∫†CH
# =========================
def clean_item(item):
    """Chu·∫©n h√≥a 1 record."""
    item["tieu_de"] = clean_space(normalize_unicode(item.get("tieu_de", "")))
    item["url_goc"] = clean_space(item.get("url_goc", ""))
    item["noi_dung"] = normalize_unicode(item.get("noi_dung", ""))

    if not isinstance(item.get("thuoc_tinh"), dict):
        item["thuoc_tinh"] = {}

    for k, v in list(item["thuoc_tinh"].items()):
        if isinstance(v, str):
            item["thuoc_tinh"][k] = clean_space(normalize_unicode(v))
        else:
            item["thuoc_tinh"][k] = str(v)

    return item

# =========================
# üöÄ MAIN
# =========================
def main():
    seen = {}
    duplicate_groups = defaultdict(list)
    total, kept, skip = 0, 0, 0

    with open(INPUT_FILE, "r", encoding="utf-8") as fin, \
         open(OUTPUT_FILE, "w", encoding="utf-8") as fout, \
         open(LOG_FILE, "w", encoding="utf-8") as flog:

        for line in tqdm(fin, desc="üîç Cleaning data"):
            total += 1
            line = line.strip()
            if not line: 
                continue

            try:
                item = json.loads(line)
            except Exception as e:
                flog.write(f"L·ªói JSON d√≤ng {total}: {repr(e)}\n")
                skip += 1
                continue

            item = clean_item(item)
            uid = get_unique_id(item)

            # b·ªè vƒÉn b·∫£n kh√¥ng c√≥ n·ªôi dung
            if len(item.get("noi_dung", "").strip()) < 200:
                flog.write(f"B·ªè vƒÉn b·∫£n tr·ªëng: {uid}\n")
                skip += 1
                continue

            # n·∫øu tr√πng th√¨ gi·ªØ b·∫£n d√†i h∆°n
            if uid in seen:
                old = seen[uid]
                if len(item["noi_dung"]) > len(old["noi_dung"]):
                    duplicate_groups[uid].append(old)
                    seen[uid] = item
                else:
                    duplicate_groups[uid].append(item)
            else:
                seen[uid] = item

        # ghi file k·∫øt qu·∫£
        for uid, it in seen.items():
            it["unique_id"] = uid
            fout.write(json.dumps(it, ensure_ascii=False) + "\n")
            kept += 1

        # ghi log duplicates
        flog.write("\n=== DUPLICATE SUMMARY ===\n")
        for uid, group in duplicate_groups.items():
            flog.write(f"{uid}: {len(group)} b·∫£n tr√πng\n")

    print("‚úÖ Ho√†n t·∫•t l√†m s·∫°ch!")
    print(f"‚Ä¢ T·ªïng ƒë·ªçc: {total:,}")
    print(f"‚Ä¢ Gi·ªØ l·∫°i: {kept:,}")
    print(f"‚Ä¢ B·ªè qua (tr·ªëng/l·ªói): {skip:,}")
    print(f"‚Ä¢ Duplicate nh√≥m: {len(duplicate_groups):,}")
    print(f"‚Ä¢ File s·∫°ch: {OUTPUT_FILE}")
    print(f"‚Ä¢ Log: {LOG_FILE}")

if __name__ == "__main__":
    main()
